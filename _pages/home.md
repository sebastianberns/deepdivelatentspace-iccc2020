---
permalink: /
title: "A Deep Dive into Latent Space: Image Generation and Manipulation with StyleGAN2"
excerpt: "Home"
author_profile: true
redirect_from:
  - /home/
  - /home.html
---

This tutorial introduces the concept of latent spaces in deep generative models, specifically StyleGAN2, and the possibilities of image generation and manipulation they provide. Focusing on a model trained on photographs of human faces, we will demonstrate how to localise the latent representation of a given image (e.g. a participantâ€™s own face) in order to blend it with another and how to create an animation of the interpolation between the two.

[Sebastian Berns](https://sebastianberns.com), Queen Mary University of London<br>
[Terence Broad](https://terencebroad.com), Goldsmiths, University of London

Tutorial Structure
======
The tutorial is set up around an online code notebook and presented in two parts. The first part gives an overview of theory and technical background knowledge, and the second is a guided walk through the exercises in the notebook.

Tutorial Part One
======
Exercises in this tutorial are based on a pre-trained StyleGAN2 model, which employs particular architectural choices. The first part of the tutorial provides an overview over the progressive improvements and changes that helped evolve the original GAN proposal into the current state-of-the-art networks. The topics covered here build the base for a better technical understanding of the exercises in the second part of the tutorial.

Tutorial Part Two
======



Practical Information
======
The oral presentations of both parts will be pre-recorded and made available to participants along with the code notebook ahead of time. On the day of the tutorial the presenters will be available for live Q&A in two separate sessions to cover as many time zones as possible.
